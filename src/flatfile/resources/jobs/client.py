# This file was auto-generated by Fern from our API Definition.

import typing
import urllib.parse
from json.decoder import JSONDecodeError

from ...core.api_error import ApiError
from ...core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ...core.jsonable_encoder import jsonable_encoder
from ...core.remove_none_from_dict import remove_none_from_dict
from ..commons.types.environment_id import EnvironmentId
from ..commons.types.file_id import FileId
from ..commons.types.job_id import JobId
from ..commons.types.sort_direction import SortDirection
from ..commons.types.space_id import SpaceId
from ..commons.types.success import Success
from ..commons.types.workbook_id import WorkbookId
from .types.job_ack_details import JobAckDetails
from .types.job_cancel_details import JobCancelDetails
from .types.job_complete_details import JobCompleteDetails
from .types.job_config import JobConfig
from .types.job_execution_plan_config_request import JobExecutionPlanConfigRequest
from .types.job_execution_plan_request import JobExecutionPlanRequest
from .types.job_plan_response import JobPlanResponse
from .types.job_response import JobResponse
from .types.job_split_details import JobSplitDetails
from .types.job_update import JobUpdate
from .types.list_jobs_response import ListJobsResponse

try:
    import pydantic.v1 as pydantic  # type: ignore
except ImportError:
    import pydantic  # type: ignore

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class JobsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def list(
        self,
        *,
        environment_id: typing.Optional[EnvironmentId] = None,
        space_id: typing.Optional[SpaceId] = None,
        workbook_id: typing.Optional[WorkbookId] = None,
        file_id: typing.Optional[FileId] = None,
        parent_id: typing.Optional[JobId] = None,
        page_size: typing.Optional[int] = None,
        page_number: typing.Optional[int] = None,
        sort_direction: typing.Optional[SortDirection] = None,
    ) -> ListJobsResponse:
        """
        Parameters:
            - environment_id: typing.Optional[EnvironmentId]. When provided, only jobs for the given environment will be returned

            - space_id: typing.Optional[SpaceId]. When provided, only jobs for the given space will be returned

            - workbook_id: typing.Optional[WorkbookId]. When provided, only jobs for the given workbook will be returned

            - file_id: typing.Optional[FileId]. When provided, only jobs for the given file will be returned

            - parent_id: typing.Optional[JobId]. When provided, only jobs that are parts of the given job will be returned

            - page_size: typing.Optional[int]. Number of jobs to return in a page (default 20)

            - page_number: typing.Optional[int]. Based on pageSize, which page of jobs to return

            - sort_direction: typing.Optional[SortDirection]. Sort direction - asc (ascending) or desc (descending)
        ---
        from flatfile.client import Flatfile

        client = Flatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        client.jobs.list(
            environment_id="us_env_YOUR_ID",
            space_id="us_sp_YOUR_ID",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "jobs"),
            params=remove_none_from_dict(
                {
                    "environmentId": environment_id,
                    "spaceId": space_id,
                    "workbookId": workbook_id,
                    "fileId": file_id,
                    "parentId": parent_id,
                    "pageSize": page_size,
                    "pageNumber": page_number,
                    "sortDirection": sort_direction,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ListJobsResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create(self, *, request: JobConfig) -> JobResponse:
        """
        Parameters:
            - request: JobConfig.
        ---
        from flatfile import JobConfig, JobType
        from flatfile.client import Flatfile

        client = Flatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        client.jobs.create(
            request=JobConfig(
                type=JobType.WORKBOOK,
                operation="submitAction",
                source="us_wb_YOUR_ID",
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "jobs"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get(self, job_id: JobId) -> JobResponse:
        """
        Parameters:
            - job_id: JobId. The id of the job to return
        ---
        from flatfile.client import Flatfile

        client = Flatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        client.jobs.get(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update(self, job_id: JobId, *, request: JobUpdate) -> JobResponse:
        """
        Parameters:
            - job_id: JobId. The id of the job to patch

            - request: JobUpdate.
        ---
        from flatfile import JobStatus, JobUpdate
        from flatfile.client import Flatfile

        client = Flatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        client.jobs.update(
            job_id="us_jb_YOUR_ID",
            request=JobUpdate(
                status=JobStatus.COMPLETE,
                progress=100,
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "PATCH",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete(self, job_id: JobId) -> Success:
        """
        Parameters:
            - job_id: JobId. The id of the job to delete
        ---
        from flatfile.client import Flatfile

        client = Flatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        client.jobs.delete(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(Success, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def execute(self, job_id: str) -> Success:
        """
        Execute a job and return the job

        Parameters:
            - job_id: str. ID of job to return
        ---
        from flatfile.client import Flatfile

        client = Flatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        client.jobs.execute(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/execute"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(Success, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_execution_plan(self, job_id: JobId) -> JobPlanResponse:
        """
        Returns a single job's execution plan

        Parameters:
            - job_id: JobId. ID of job to return
        ---
        from flatfile.client import Flatfile

        client = Flatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        client.jobs.get_execution_plan(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/plan"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobPlanResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_execution_plan(self, job_id: JobId, *, request: JobExecutionPlanRequest) -> JobPlanResponse:
        """
        Update a job's entire execution plan

        Parameters:
            - job_id: JobId. ID of job to return

            - request: JobExecutionPlanRequest.
        ---
        from flatfile import (
            DestinationField,
            Edge,
            JobExecutionPlanRequest,
            Property_String,
            SourceField,
        )
        from flatfile.client import Flatfile

        client = Flatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        client.jobs.update_execution_plan(
            job_id="us_jb_YOUR_ID",
            request=JobExecutionPlanRequest(
                field_mapping=[
                    Edge(
                        source_field=Property_String(
                            type="string",
                            key="firstName",
                        ),
                        destination_field=Property_String(
                            type="string",
                            key="firstName",
                            label="First Name",
                        ),
                    ),
                    Edge(
                        source_field=Property_String(
                            type="string",
                            key="lastName",
                        ),
                        destination_field=Property_String(
                            type="string",
                            key="lastName",
                            label="Last Name",
                        ),
                    ),
                ],
                unmapped_source_fields=[
                    SourceField(
                        source_field=Property_String(
                            type="string",
                            key="email",
                        ),
                    )
                ],
                unmapped_destination_fields=[
                    DestinationField(
                        destination_field=Property_String(
                            type="string",
                            key="email",
                            label="Email",
                        ),
                    )
                ],
                file_id="us_fl_YOUR_ID",
                job_id="us_jb_YOUR_ID",
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/plan"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobPlanResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_execution_plan_fields(self, job_id: str, *, request: JobExecutionPlanConfigRequest) -> JobPlanResponse:
        """
        Update one or more individual fields on a job's execution plan

        Parameters:
            - job_id: str. ID of job to return

            - request: JobExecutionPlanConfigRequest.
        """
        _response = self._client_wrapper.httpx_client.request(
            "PATCH",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/plan"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobPlanResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def ack(self, job_id: JobId, *, request: typing.Optional[JobAckDetails] = None) -> JobResponse:
        """
        Acknowledge a job and return the job

        Parameters:
            - job_id: JobId. ID of job to return

            - request: typing.Optional[JobAckDetails].
        ---
        import datetime

        from flatfile import JobAckDetails
        from flatfile.client import Flatfile

        client = Flatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        client.jobs.ack(
            job_id="us_jb_YOUR_ID",
            request=JobAckDetails(
                info="Acknowledged by user",
                progress=100,
                estimated_completion_at=datetime.datetime.fromisoformat(
                    "2023-10-30 20:04:32.074000+00:00",
                ),
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/ack"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def ack_outcome(self, job_id: JobId) -> JobResponse:
        """
        Acknowledge a job outcome and return the job

        Parameters:
            - job_id: JobId. ID of job to return
        ---
        from flatfile.client import Flatfile

        client = Flatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        client.jobs.ack_outcome(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/outcome/ack"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def complete(self, job_id: JobId, *, request: typing.Optional[JobCompleteDetails] = None) -> JobResponse:
        """
        Complete a job and return the job

        Parameters:
            - job_id: JobId. ID of job to return

            - request: typing.Optional[JobCompleteDetails].
        ---
        from flatfile import JobCompleteDetails, JobOutcome, JobOutcomeNext_Id
        from flatfile.client import Flatfile

        client = Flatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        client.jobs.complete(
            job_id="us_jb_YOUR_ID",
            request=JobCompleteDetails(
                outcome=JobOutcome(
                    acknowledge=True,
                    button_text="Acknowledge",
                    next=JobOutcomeNext_Id(
                        type="id",
                        id="us_jb_YOUR_ID",
                    ),
                    heading="Success",
                    message="Job was successful",
                ),
                info="Job is Complete",
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/complete"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def fail(self, job_id: JobId, *, request: typing.Optional[JobCompleteDetails] = None) -> JobResponse:
        """
        Fail a job and return the job

        Parameters:
            - job_id: JobId. ID of job to return

            - request: typing.Optional[JobCompleteDetails].
        ---
        from flatfile import JobCompleteDetails, JobOutcome, JobOutcomeNext_Id
        from flatfile.client import Flatfile

        client = Flatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        client.jobs.fail(
            job_id="us_jb_YOUR_ID",
            request=JobCompleteDetails(
                outcome=JobOutcome(
                    acknowledge=True,
                    button_text="Acknowledge",
                    next=JobOutcomeNext_Id(
                        type="id",
                        id="us_jb_YOUR_ID",
                    ),
                    heading="Failed",
                    message="Job failed",
                ),
                info="Job was failed",
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/fail"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def cancel(self, job_id: JobId, *, request: typing.Optional[JobCancelDetails] = None) -> JobResponse:
        """
        Cancel a job and return the job

        Parameters:
            - job_id: JobId. ID of job to return

            - request: typing.Optional[JobCancelDetails].
        ---
        from flatfile import JobCancelDetails
        from flatfile.client import Flatfile

        client = Flatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        client.jobs.cancel(
            job_id="us_jb_YOUR_ID",
            request=JobCancelDetails(
                info="Job was canceled",
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/cancel"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def split(self, job_id: JobId, *, request: JobSplitDetails) -> JobResponse:
        """
        Split a job and return the job

        Parameters:
            - job_id: JobId. ID of job to return

            - request: JobSplitDetails.
        ---
        from flatfile import JobSplitDetails
        from flatfile.client import Flatfile

        client = Flatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        client.jobs.split(
            job_id="us_jb_YOUR_ID",
            request=JobSplitDetails(
                run_in_parallel=True,
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/split"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncJobsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def list(
        self,
        *,
        environment_id: typing.Optional[EnvironmentId] = None,
        space_id: typing.Optional[SpaceId] = None,
        workbook_id: typing.Optional[WorkbookId] = None,
        file_id: typing.Optional[FileId] = None,
        parent_id: typing.Optional[JobId] = None,
        page_size: typing.Optional[int] = None,
        page_number: typing.Optional[int] = None,
        sort_direction: typing.Optional[SortDirection] = None,
    ) -> ListJobsResponse:
        """
        Parameters:
            - environment_id: typing.Optional[EnvironmentId]. When provided, only jobs for the given environment will be returned

            - space_id: typing.Optional[SpaceId]. When provided, only jobs for the given space will be returned

            - workbook_id: typing.Optional[WorkbookId]. When provided, only jobs for the given workbook will be returned

            - file_id: typing.Optional[FileId]. When provided, only jobs for the given file will be returned

            - parent_id: typing.Optional[JobId]. When provided, only jobs that are parts of the given job will be returned

            - page_size: typing.Optional[int]. Number of jobs to return in a page (default 20)

            - page_number: typing.Optional[int]. Based on pageSize, which page of jobs to return

            - sort_direction: typing.Optional[SortDirection]. Sort direction - asc (ascending) or desc (descending)
        ---
        from flatfile.client import AsyncFlatfile

        client = AsyncFlatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        await client.jobs.list(
            environment_id="us_env_YOUR_ID",
            space_id="us_sp_YOUR_ID",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "jobs"),
            params=remove_none_from_dict(
                {
                    "environmentId": environment_id,
                    "spaceId": space_id,
                    "workbookId": workbook_id,
                    "fileId": file_id,
                    "parentId": parent_id,
                    "pageSize": page_size,
                    "pageNumber": page_number,
                    "sortDirection": sort_direction,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ListJobsResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create(self, *, request: JobConfig) -> JobResponse:
        """
        Parameters:
            - request: JobConfig.
        ---
        from flatfile import JobConfig, JobType
        from flatfile.client import AsyncFlatfile

        client = AsyncFlatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        await client.jobs.create(
            request=JobConfig(
                type=JobType.WORKBOOK,
                operation="submitAction",
                source="us_wb_YOUR_ID",
            ),
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "jobs"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get(self, job_id: JobId) -> JobResponse:
        """
        Parameters:
            - job_id: JobId. The id of the job to return
        ---
        from flatfile.client import AsyncFlatfile

        client = AsyncFlatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        await client.jobs.get(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update(self, job_id: JobId, *, request: JobUpdate) -> JobResponse:
        """
        Parameters:
            - job_id: JobId. The id of the job to patch

            - request: JobUpdate.
        ---
        from flatfile import JobStatus, JobUpdate
        from flatfile.client import AsyncFlatfile

        client = AsyncFlatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        await client.jobs.update(
            job_id="us_jb_YOUR_ID",
            request=JobUpdate(
                status=JobStatus.COMPLETE,
                progress=100,
            ),
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "PATCH",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete(self, job_id: JobId) -> Success:
        """
        Parameters:
            - job_id: JobId. The id of the job to delete
        ---
        from flatfile.client import AsyncFlatfile

        client = AsyncFlatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        await client.jobs.delete(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(Success, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def execute(self, job_id: str) -> Success:
        """
        Execute a job and return the job

        Parameters:
            - job_id: str. ID of job to return
        ---
        from flatfile.client import AsyncFlatfile

        client = AsyncFlatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        await client.jobs.execute(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/execute"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(Success, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_execution_plan(self, job_id: JobId) -> JobPlanResponse:
        """
        Returns a single job's execution plan

        Parameters:
            - job_id: JobId. ID of job to return
        ---
        from flatfile.client import AsyncFlatfile

        client = AsyncFlatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        await client.jobs.get_execution_plan(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/plan"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobPlanResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_execution_plan(self, job_id: JobId, *, request: JobExecutionPlanRequest) -> JobPlanResponse:
        """
        Update a job's entire execution plan

        Parameters:
            - job_id: JobId. ID of job to return

            - request: JobExecutionPlanRequest.
        ---
        from flatfile import (
            DestinationField,
            Edge,
            JobExecutionPlanRequest,
            Property_String,
            SourceField,
        )
        from flatfile.client import AsyncFlatfile

        client = AsyncFlatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        await client.jobs.update_execution_plan(
            job_id="us_jb_YOUR_ID",
            request=JobExecutionPlanRequest(
                field_mapping=[
                    Edge(
                        source_field=Property_String(
                            type="string",
                            key="firstName",
                        ),
                        destination_field=Property_String(
                            type="string",
                            key="firstName",
                            label="First Name",
                        ),
                    ),
                    Edge(
                        source_field=Property_String(
                            type="string",
                            key="lastName",
                        ),
                        destination_field=Property_String(
                            type="string",
                            key="lastName",
                            label="Last Name",
                        ),
                    ),
                ],
                unmapped_source_fields=[
                    SourceField(
                        source_field=Property_String(
                            type="string",
                            key="email",
                        ),
                    )
                ],
                unmapped_destination_fields=[
                    DestinationField(
                        destination_field=Property_String(
                            type="string",
                            key="email",
                            label="Email",
                        ),
                    )
                ],
                file_id="us_fl_YOUR_ID",
                job_id="us_jb_YOUR_ID",
            ),
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/plan"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobPlanResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_execution_plan_fields(
        self, job_id: str, *, request: JobExecutionPlanConfigRequest
    ) -> JobPlanResponse:
        """
        Update one or more individual fields on a job's execution plan

        Parameters:
            - job_id: str. ID of job to return

            - request: JobExecutionPlanConfigRequest.
        """
        _response = await self._client_wrapper.httpx_client.request(
            "PATCH",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/plan"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobPlanResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def ack(self, job_id: JobId, *, request: typing.Optional[JobAckDetails] = None) -> JobResponse:
        """
        Acknowledge a job and return the job

        Parameters:
            - job_id: JobId. ID of job to return

            - request: typing.Optional[JobAckDetails].
        ---
        import datetime

        from flatfile import JobAckDetails
        from flatfile.client import AsyncFlatfile

        client = AsyncFlatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        await client.jobs.ack(
            job_id="us_jb_YOUR_ID",
            request=JobAckDetails(
                info="Acknowledged by user",
                progress=100,
                estimated_completion_at=datetime.datetime.fromisoformat(
                    "2023-10-30 20:04:32.074000+00:00",
                ),
            ),
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/ack"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def ack_outcome(self, job_id: JobId) -> JobResponse:
        """
        Acknowledge a job outcome and return the job

        Parameters:
            - job_id: JobId. ID of job to return
        ---
        from flatfile.client import AsyncFlatfile

        client = AsyncFlatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        await client.jobs.ack_outcome(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/outcome/ack"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def complete(self, job_id: JobId, *, request: typing.Optional[JobCompleteDetails] = None) -> JobResponse:
        """
        Complete a job and return the job

        Parameters:
            - job_id: JobId. ID of job to return

            - request: typing.Optional[JobCompleteDetails].
        ---
        from flatfile import JobCompleteDetails, JobOutcome, JobOutcomeNext_Id
        from flatfile.client import AsyncFlatfile

        client = AsyncFlatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        await client.jobs.complete(
            job_id="us_jb_YOUR_ID",
            request=JobCompleteDetails(
                outcome=JobOutcome(
                    acknowledge=True,
                    button_text="Acknowledge",
                    next=JobOutcomeNext_Id(
                        type="id",
                        id="us_jb_YOUR_ID",
                    ),
                    heading="Success",
                    message="Job was successful",
                ),
                info="Job is Complete",
            ),
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/complete"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def fail(self, job_id: JobId, *, request: typing.Optional[JobCompleteDetails] = None) -> JobResponse:
        """
        Fail a job and return the job

        Parameters:
            - job_id: JobId. ID of job to return

            - request: typing.Optional[JobCompleteDetails].
        ---
        from flatfile import JobCompleteDetails, JobOutcome, JobOutcomeNext_Id
        from flatfile.client import AsyncFlatfile

        client = AsyncFlatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        await client.jobs.fail(
            job_id="us_jb_YOUR_ID",
            request=JobCompleteDetails(
                outcome=JobOutcome(
                    acknowledge=True,
                    button_text="Acknowledge",
                    next=JobOutcomeNext_Id(
                        type="id",
                        id="us_jb_YOUR_ID",
                    ),
                    heading="Failed",
                    message="Job failed",
                ),
                info="Job was failed",
            ),
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/fail"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def cancel(self, job_id: JobId, *, request: typing.Optional[JobCancelDetails] = None) -> JobResponse:
        """
        Cancel a job and return the job

        Parameters:
            - job_id: JobId. ID of job to return

            - request: typing.Optional[JobCancelDetails].
        ---
        from flatfile import JobCancelDetails
        from flatfile.client import AsyncFlatfile

        client = AsyncFlatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        await client.jobs.cancel(
            job_id="us_jb_YOUR_ID",
            request=JobCancelDetails(
                info="Job was canceled",
            ),
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/cancel"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def split(self, job_id: JobId, *, request: JobSplitDetails) -> JobResponse:
        """
        Split a job and return the job

        Parameters:
            - job_id: JobId. ID of job to return

            - request: JobSplitDetails.
        ---
        from flatfile import JobSplitDetails
        from flatfile.client import AsyncFlatfile

        client = AsyncFlatfile(
            x_disable_hooks="YOUR_X_DISABLE_HOOKS",
            token="YOUR_TOKEN",
        )
        await client.jobs.split(
            job_id="us_jb_YOUR_ID",
            request=JobSplitDetails(
                run_in_parallel=True,
            ),
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"jobs/{job_id}/split"),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(JobResponse, _response.json())  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
