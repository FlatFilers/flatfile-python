# This file was auto-generated by Fern from our API Definition.

import typing
from ..core.client_wrapper import SyncClientWrapper
from ..commons.types.environment_id import EnvironmentId
from ..commons.types.space_id import SpaceId
from ..commons.types.workbook_id import WorkbookId
from ..commons.types.file_id import FileId
from ..commons.types.job_id import JobId
from ..commons.types.sort_direction import SortDirection
from ..core.request_options import RequestOptions
from .types.list_jobs_response import ListJobsResponse
from ..core.pydantic_utilities import parse_obj_as
from json.decoder import JSONDecodeError
from ..core.api_error import ApiError
from .types.job_type import JobType
from .types.job_source import JobSource
from .types.job_destination import JobDestination
from .types.job_update_config import JobUpdateConfig
from .types.trigger import Trigger
from .types.job_status import JobStatus
from .types.job_mode import JobMode
from .types.job_subject import JobSubject
from .types.job_part_execution import JobPartExecution
from .types.job_response import JobResponse
from ..core.serialization import convert_and_respect_annotation_metadata
from ..core.jsonable_encoder import jsonable_encoder
import datetime as dt
from ..commons.types.success import Success
from .types.job_plan_response import JobPlanResponse
from .types.edge import Edge
from .types.source_field import SourceField
from .types.destination_field import DestinationField
from .types.job_ack_details import JobAckDetails
from .types.job_complete_details import JobCompleteDetails
from .types.job_cancel_details import JobCancelDetails
from ..commons.types.sheet_id import SheetId
from ..commons.types.filter import Filter
from ..commons.types.filter_field import FilterField
from ..commons.types.search_value import SearchValue
from ..commons.types.search_field import SearchField
from ..commons.types.record_id import RecordId
from ..records.types.diff_records_response import DiffRecordsResponse
from .types.job_parts import JobParts
from ..core.client_wrapper import AsyncClientWrapper

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class JobsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def list(
        self,
        *,
        environment_id: typing.Optional[EnvironmentId] = None,
        space_id: typing.Optional[SpaceId] = None,
        workbook_id: typing.Optional[WorkbookId] = None,
        file_id: typing.Optional[FileId] = None,
        parent_id: typing.Optional[JobId] = None,
        page_size: typing.Optional[int] = None,
        page_number: typing.Optional[int] = None,
        sort_direction: typing.Optional[SortDirection] = None,
        exclude_child_jobs: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ListJobsResponse:
        """
        Parameters
        ----------
        environment_id : typing.Optional[EnvironmentId]
            When provided, only jobs for the given environment will be returned

        space_id : typing.Optional[SpaceId]
            When provided, only jobs for the given space will be returned

        workbook_id : typing.Optional[WorkbookId]
            When provided, only jobs for the given workbook will be returned

        file_id : typing.Optional[FileId]
            When provided, only jobs for the given file will be returned

        parent_id : typing.Optional[JobId]
            When provided, only jobs that are parts of the given job will be returned

        page_size : typing.Optional[int]
            Number of jobs to return in a page (default 20)

        page_number : typing.Optional[int]
            Based on pageSize, which page of jobs to return

        sort_direction : typing.Optional[SortDirection]
            Sort direction - asc (ascending) or desc (descending)

        exclude_child_jobs : typing.Optional[bool]
            When true, only top-level jobs will be returned unless a parentId is specified

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ListJobsResponse

        Examples
        --------
        from flatfile import Flatfile

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.list(
            environment_id="us_env_YOUR_ID",
            space_id="us_sp_YOUR_ID",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "jobs",
            method="GET",
            params={
                "environmentId": environment_id,
                "spaceId": space_id,
                "workbookId": workbook_id,
                "fileId": file_id,
                "parentId": parent_id,
                "pageSize": page_size,
                "pageNumber": page_number,
                "sortDirection": sort_direction,
                "excludeChildJobs": exclude_child_jobs,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ListJobsResponse,
                    parse_obj_as(
                        type_=ListJobsResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create(
        self,
        *,
        type: JobType,
        operation: str,
        source: JobSource,
        destination: typing.Optional[JobDestination] = OMIT,
        config: typing.Optional[JobUpdateConfig] = OMIT,
        trigger: typing.Optional[Trigger] = OMIT,
        status: typing.Optional[JobStatus] = OMIT,
        progress: typing.Optional[int] = OMIT,
        file_id: typing.Optional[FileId] = OMIT,
        mode: typing.Optional[JobMode] = OMIT,
        input: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        subject: typing.Optional[JobSubject] = OMIT,
        outcome: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        info: typing.Optional[str] = OMIT,
        managed: typing.Optional[bool] = OMIT,
        environment_id: typing.Optional[EnvironmentId] = OMIT,
        part: typing.Optional[int] = OMIT,
        part_data: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        part_execution: typing.Optional[JobPartExecution] = OMIT,
        parent_id: typing.Optional[JobId] = OMIT,
        predecessor_ids: typing.Optional[typing.Sequence[JobId]] = OMIT,
        metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobResponse:
        """
        Parameters
        ----------
        type : JobType
            The type of job

        operation : str
            the type of operation to perform on the data. For example, "export".

        source : JobSource

        destination : typing.Optional[JobDestination]

        config : typing.Optional[JobUpdateConfig]

        trigger : typing.Optional[Trigger]
            the type of trigger to use for this job

        status : typing.Optional[JobStatus]
            the status of the job

        progress : typing.Optional[int]
            the progress of the job. Whole number between 0 and 100

        file_id : typing.Optional[FileId]

        mode : typing.Optional[JobMode]
            the mode of the job

        input : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Input parameters for this job type.

        subject : typing.Optional[JobSubject]
            Subject parameters for this job type.

        outcome : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Outcome summary of job.

        info : typing.Optional[str]
            Current status of job in text

        managed : typing.Optional[bool]
            Indicates if Flatfile is managing the control flow of this job or if it is being manually tracked.

        environment_id : typing.Optional[EnvironmentId]
            The id of the environment this job belongs to

        part : typing.Optional[int]
            The part number of this job

        part_data : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            The data for this part of the job

        part_execution : typing.Optional[JobPartExecution]
            The execution mode for this part of the job

        parent_id : typing.Optional[JobId]
            The id of the parent job

        predecessor_ids : typing.Optional[typing.Sequence[JobId]]
            The ids of the jobs that must complete before this job can start

        metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Additional metadata for the job

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        from flatfile import Flatfile

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.create(
            type="workbook",
            operation="submitAction",
            source="us_wb_YOUR_ID",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "jobs",
            method="POST",
            json={
                "type": type,
                "operation": operation,
                "source": source,
                "destination": destination,
                "config": convert_and_respect_annotation_metadata(
                    object_=config, annotation=JobUpdateConfig, direction="write"
                ),
                "trigger": trigger,
                "status": status,
                "progress": progress,
                "fileId": file_id,
                "mode": mode,
                "input": input,
                "subject": convert_and_respect_annotation_metadata(
                    object_=subject, annotation=JobSubject, direction="write"
                ),
                "outcome": outcome,
                "info": info,
                "managed": managed,
                "environmentId": environment_id,
                "part": part,
                "partData": part_data,
                "partExecution": part_execution,
                "parentId": parent_id,
                "predecessorIds": predecessor_ids,
                "metadata": metadata,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get(self, job_id: JobId, *, request_options: typing.Optional[RequestOptions] = None) -> JobResponse:
        """
        Parameters
        ----------
        job_id : JobId
            The id of the job to return

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        from flatfile import Flatfile

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.get(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update(
        self,
        job_id: JobId,
        *,
        config: typing.Optional[JobUpdateConfig] = OMIT,
        status: typing.Optional[JobStatus] = OMIT,
        progress: typing.Optional[int] = OMIT,
        outcome_acknowledged_at: typing.Optional[dt.datetime] = OMIT,
        info: typing.Optional[str] = OMIT,
        metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobResponse:
        """
        Parameters
        ----------
        job_id : JobId
            The id of the job to patch

        config : typing.Optional[JobUpdateConfig]

        status : typing.Optional[JobStatus]
            the status of the job

        progress : typing.Optional[int]
            the progress of the job. Whole number between 0 and 100

        outcome_acknowledged_at : typing.Optional[dt.datetime]
            the time that the job's outcome has been acknowledged by a user

        info : typing.Optional[str]
            Current status of job in text

        metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Additional metadata for the job

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        from flatfile import Flatfile
        from flatfile.jobs import EmptyObject

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.update(
            job_id="us_jb_YOUR_ID",
            config=EmptyObject(),
            status="complete",
            progress=100,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}",
            method="PATCH",
            json={
                "config": convert_and_respect_annotation_metadata(
                    object_=config, annotation=JobUpdateConfig, direction="write"
                ),
                "status": status,
                "progress": progress,
                "outcomeAcknowledgedAt": outcome_acknowledged_at,
                "info": info,
                "metadata": metadata,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete(self, job_id: JobId, *, request_options: typing.Optional[RequestOptions] = None) -> Success:
        """
        Parameters
        ----------
        job_id : JobId
            The id of the job to delete

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Success

        Examples
        --------
        from flatfile import Flatfile

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.delete(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    Success,
                    parse_obj_as(
                        type_=Success,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def execute(self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None) -> Success:
        """
        Execute a job and return the job

        Parameters
        ----------
        job_id : str
            ID of job to return

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Success

        Examples
        --------
        from flatfile import Flatfile

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.execute(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/execute",
            method="POST",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    Success,
                    parse_obj_as(
                        type_=Success,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_execution_plan(
        self, job_id: JobId, *, request_options: typing.Optional[RequestOptions] = None
    ) -> JobPlanResponse:
        """
        Returns a single job's execution plan

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobPlanResponse

        Examples
        --------
        from flatfile import Flatfile

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.get_execution_plan(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/plan",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobPlanResponse,
                    parse_obj_as(
                        type_=JobPlanResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_execution_plan(
        self,
        job_id_: JobId,
        *,
        file_id: FileId,
        job_id: JobId,
        field_mapping: typing.Sequence[Edge],
        unmapped_source_fields: typing.Sequence[SourceField],
        unmapped_destination_fields: typing.Sequence[DestinationField],
        program_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobPlanResponse:
        """
        Update a job's entire execution plan

        Parameters
        ----------
        job_id_ : JobId
            ID of job to return

        file_id : FileId

        job_id : JobId

        field_mapping : typing.Sequence[Edge]

        unmapped_source_fields : typing.Sequence[SourceField]

        unmapped_destination_fields : typing.Sequence[DestinationField]

        program_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobPlanResponse

        Examples
        --------
        from flatfile import Flatfile
        from flatfile.jobs import DestinationField, Edge, SourceField
        from flatfile.property import Property_String

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.update_execution_plan(
            job_id_="us_jb_YOUR_ID",
            field_mapping=[
                Edge(
                    source_field=Property_String(
                        key="firstName",
                    ),
                    destination_field=Property_String(
                        key="firstName",
                        label="First Name",
                    ),
                ),
                Edge(
                    source_field=Property_String(
                        key="lastName",
                    ),
                    destination_field=Property_String(
                        key="lastName",
                        label="Last Name",
                    ),
                ),
            ],
            unmapped_source_fields=[
                SourceField(
                    source_field=Property_String(
                        key="email",
                    ),
                )
            ],
            unmapped_destination_fields=[
                DestinationField(
                    destination_field=Property_String(
                        key="email",
                        label="Email",
                    ),
                )
            ],
            file_id="us_fl_YOUR_ID",
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id_)}/plan",
            method="PUT",
            json={
                "fileId": file_id,
                "jobId": job_id,
                "fieldMapping": convert_and_respect_annotation_metadata(
                    object_=field_mapping, annotation=typing.Sequence[Edge], direction="write"
                ),
                "unmappedSourceFields": convert_and_respect_annotation_metadata(
                    object_=unmapped_source_fields, annotation=typing.Sequence[SourceField], direction="write"
                ),
                "unmappedDestinationFields": convert_and_respect_annotation_metadata(
                    object_=unmapped_destination_fields, annotation=typing.Sequence[DestinationField], direction="write"
                ),
                "programId": program_id,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobPlanResponse,
                    parse_obj_as(
                        type_=JobPlanResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_execution_plan_fields(
        self,
        job_id_: str,
        *,
        file_id: FileId,
        job_id: JobId,
        field_mapping: typing.Optional[typing.Sequence[Edge]] = OMIT,
        unmapped_source_fields: typing.Optional[typing.Sequence[SourceField]] = OMIT,
        unmapped_destination_fields: typing.Optional[typing.Sequence[DestinationField]] = OMIT,
        program_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobPlanResponse:
        """
        Update one or more individual fields on a job's execution plan

        Parameters
        ----------
        job_id_ : str
            ID of job to return

        file_id : FileId

        job_id : JobId

        field_mapping : typing.Optional[typing.Sequence[Edge]]

        unmapped_source_fields : typing.Optional[typing.Sequence[SourceField]]

        unmapped_destination_fields : typing.Optional[typing.Sequence[DestinationField]]

        program_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobPlanResponse

        Examples
        --------
        from flatfile import Flatfile

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.update_execution_plan_fields(
            job_id_="jobId",
            file_id="fileId",
            job_id="jobId",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id_)}/plan",
            method="PATCH",
            json={
                "fileId": file_id,
                "jobId": job_id,
                "fieldMapping": convert_and_respect_annotation_metadata(
                    object_=field_mapping, annotation=typing.Sequence[Edge], direction="write"
                ),
                "unmappedSourceFields": convert_and_respect_annotation_metadata(
                    object_=unmapped_source_fields, annotation=typing.Sequence[SourceField], direction="write"
                ),
                "unmappedDestinationFields": convert_and_respect_annotation_metadata(
                    object_=unmapped_destination_fields, annotation=typing.Sequence[DestinationField], direction="write"
                ),
                "programId": program_id,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobPlanResponse,
                    parse_obj_as(
                        type_=JobPlanResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def ack(
        self,
        job_id: JobId,
        *,
        request: typing.Optional[JobAckDetails] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobResponse:
        """
        Acknowledge a job and return the job

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        request : typing.Optional[JobAckDetails]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        import datetime

        from flatfile import Flatfile
        from flatfile.jobs import JobAckDetails

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.ack(
            job_id="us_jb_YOUR_ID",
            request=JobAckDetails(
                info="Acknowledged by user",
                progress=100,
                estimated_completion_at=datetime.datetime.fromisoformat(
                    "2023-10-30 20:04:32.074000+00:00",
                ),
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/ack",
            method="POST",
            json=convert_and_respect_annotation_metadata(object_=request, annotation=JobAckDetails, direction="write"),
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def ack_outcome(self, job_id: JobId, *, request_options: typing.Optional[RequestOptions] = None) -> JobResponse:
        """
        Acknowledge a job outcome and return the job

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        from flatfile import Flatfile

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.ack_outcome(
            job_id="us_jb_YOUR_ID",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/outcome/ack",
            method="POST",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def complete(
        self,
        job_id: JobId,
        *,
        request: typing.Optional[JobCompleteDetails] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobResponse:
        """
        Complete a job and return the job

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        request : typing.Optional[JobCompleteDetails]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        from flatfile import Flatfile
        from flatfile.jobs import JobCompleteDetails, JobOutcome, JobOutcomeNext_Id

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.complete(
            job_id="us_jb_YOUR_ID",
            request=JobCompleteDetails(
                outcome=JobOutcome(
                    acknowledge=True,
                    button_text="Acknowledge",
                    next=JobOutcomeNext_Id(
                        id="us_jb_YOUR_ID",
                    ),
                    heading="Success",
                    message="Job was successful",
                ),
                info="Job is Complete",
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/complete",
            method="POST",
            json=convert_and_respect_annotation_metadata(
                object_=request, annotation=JobCompleteDetails, direction="write"
            ),
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def fail(
        self,
        job_id: JobId,
        *,
        request: typing.Optional[JobCompleteDetails] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobResponse:
        """
        Fail a job and return the job

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        request : typing.Optional[JobCompleteDetails]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        from flatfile import Flatfile
        from flatfile.jobs import JobCompleteDetails, JobOutcome, JobOutcomeNext_Id

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.fail(
            job_id="us_jb_YOUR_ID",
            request=JobCompleteDetails(
                outcome=JobOutcome(
                    acknowledge=True,
                    button_text="Acknowledge",
                    next=JobOutcomeNext_Id(
                        id="us_jb_YOUR_ID",
                    ),
                    heading="Failed",
                    message="Job failed",
                ),
                info="Job was failed",
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/fail",
            method="POST",
            json=convert_and_respect_annotation_metadata(
                object_=request, annotation=JobCompleteDetails, direction="write"
            ),
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def cancel(
        self,
        job_id: JobId,
        *,
        request: typing.Optional[JobCancelDetails] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobResponse:
        """
        Cancel a job and return the job

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        request : typing.Optional[JobCancelDetails]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        from flatfile import Flatfile
        from flatfile.jobs import JobCancelDetails

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.cancel(
            job_id="us_jb_YOUR_ID",
            request=JobCancelDetails(
                info="Job was canceled",
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/cancel",
            method="POST",
            json=convert_and_respect_annotation_metadata(
                object_=request, annotation=JobCancelDetails, direction="write"
            ),
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def retry(self, job_id: JobId, *, request_options: typing.Optional[RequestOptions] = None) -> JobResponse:
        """
        Retry a failt job and return the job

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        from flatfile import Flatfile

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.retry(
            job_id="jobId",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/retry",
            method="POST",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def preview_mutation(
        self,
        *,
        sheet_id: SheetId,
        mutate_record: str,
        mutation_id: typing.Optional[str] = OMIT,
        snapshot_label: typing.Optional[str] = OMIT,
        snapshot_id: typing.Optional[str] = OMIT,
        filter: typing.Optional[Filter] = OMIT,
        filter_field: typing.Optional[FilterField] = OMIT,
        search_value: typing.Optional[SearchValue] = OMIT,
        search_field: typing.Optional[SearchField] = OMIT,
        q: typing.Optional[str] = OMIT,
        ids: typing.Optional[typing.Sequence[RecordId]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> DiffRecordsResponse:
        """
        Preview the results of a mutation

        Parameters
        ----------
        sheet_id : SheetId

        mutate_record : str
            A JavaScript function that will be run on each record in the sheet, it should return a mutated record.

        mutation_id : typing.Optional[str]
            If the mutation was generated through some sort of id-ed process, this links this job and that process.

        snapshot_label : typing.Optional[str]
            If specified, a snapshot will be generated with this label

        snapshot_id : typing.Optional[str]
            The generated snapshotId will be stored here

        filter : typing.Optional[Filter]

        filter_field : typing.Optional[FilterField]

        search_value : typing.Optional[SearchValue]

        search_field : typing.Optional[SearchField]

        q : typing.Optional[str]

        ids : typing.Optional[typing.Sequence[RecordId]]
            The Record Ids param (ids) is a list of record ids that can be passed to several record endpoints allowing the user to identify specific records to INCLUDE in the query, or specific records to EXCLUDE, depending on whether or not filters are being applied. When passing a query param that filters the record dataset, such as 'searchValue', or a 'filter' of 'valid' | 'error' | 'all', the 'ids' param will EXCLUDE those records from the filtered results. For basic queries that do not filter the dataset, passing record ids in the 'ids' param will limit the dataset to INCLUDE just those specific records

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DiffRecordsResponse

        Examples
        --------
        from flatfile import Flatfile

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.preview_mutation(
            sheet_id="sheetId",
            mutate_record="mutateRecord",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "jobs/preview-mutation",
            method="POST",
            json={
                "sheetId": sheet_id,
                "mutateRecord": mutate_record,
                "mutationId": mutation_id,
                "snapshotLabel": snapshot_label,
                "snapshotId": snapshot_id,
                "filter": filter,
                "filterField": filter_field,
                "searchValue": search_value,
                "searchField": search_field,
                "q": q,
                "ids": ids,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    DiffRecordsResponse,
                    parse_obj_as(
                        type_=DiffRecordsResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def split(
        self,
        job_id: JobId,
        *,
        parts: JobParts,
        run_in_parallel: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobResponse:
        """
        Split a job and return the job

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        parts : JobParts

        run_in_parallel : typing.Optional[bool]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        from flatfile import Flatfile

        client = Flatfile(
            token="YOUR_TOKEN",
        )
        client.jobs.split(
            job_id="us_jb_YOUR_ID",
            parts=[{}],
            run_in_parallel=True,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/split",
            method="POST",
            json={
                "parts": convert_and_respect_annotation_metadata(object_=parts, annotation=JobParts, direction="write"),
                "runInParallel": run_in_parallel,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncJobsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def list(
        self,
        *,
        environment_id: typing.Optional[EnvironmentId] = None,
        space_id: typing.Optional[SpaceId] = None,
        workbook_id: typing.Optional[WorkbookId] = None,
        file_id: typing.Optional[FileId] = None,
        parent_id: typing.Optional[JobId] = None,
        page_size: typing.Optional[int] = None,
        page_number: typing.Optional[int] = None,
        sort_direction: typing.Optional[SortDirection] = None,
        exclude_child_jobs: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ListJobsResponse:
        """
        Parameters
        ----------
        environment_id : typing.Optional[EnvironmentId]
            When provided, only jobs for the given environment will be returned

        space_id : typing.Optional[SpaceId]
            When provided, only jobs for the given space will be returned

        workbook_id : typing.Optional[WorkbookId]
            When provided, only jobs for the given workbook will be returned

        file_id : typing.Optional[FileId]
            When provided, only jobs for the given file will be returned

        parent_id : typing.Optional[JobId]
            When provided, only jobs that are parts of the given job will be returned

        page_size : typing.Optional[int]
            Number of jobs to return in a page (default 20)

        page_number : typing.Optional[int]
            Based on pageSize, which page of jobs to return

        sort_direction : typing.Optional[SortDirection]
            Sort direction - asc (ascending) or desc (descending)

        exclude_child_jobs : typing.Optional[bool]
            When true, only top-level jobs will be returned unless a parentId is specified

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ListJobsResponse

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.list(
                environment_id="us_env_YOUR_ID",
                space_id="us_sp_YOUR_ID",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "jobs",
            method="GET",
            params={
                "environmentId": environment_id,
                "spaceId": space_id,
                "workbookId": workbook_id,
                "fileId": file_id,
                "parentId": parent_id,
                "pageSize": page_size,
                "pageNumber": page_number,
                "sortDirection": sort_direction,
                "excludeChildJobs": exclude_child_jobs,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ListJobsResponse,
                    parse_obj_as(
                        type_=ListJobsResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create(
        self,
        *,
        type: JobType,
        operation: str,
        source: JobSource,
        destination: typing.Optional[JobDestination] = OMIT,
        config: typing.Optional[JobUpdateConfig] = OMIT,
        trigger: typing.Optional[Trigger] = OMIT,
        status: typing.Optional[JobStatus] = OMIT,
        progress: typing.Optional[int] = OMIT,
        file_id: typing.Optional[FileId] = OMIT,
        mode: typing.Optional[JobMode] = OMIT,
        input: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        subject: typing.Optional[JobSubject] = OMIT,
        outcome: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        info: typing.Optional[str] = OMIT,
        managed: typing.Optional[bool] = OMIT,
        environment_id: typing.Optional[EnvironmentId] = OMIT,
        part: typing.Optional[int] = OMIT,
        part_data: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        part_execution: typing.Optional[JobPartExecution] = OMIT,
        parent_id: typing.Optional[JobId] = OMIT,
        predecessor_ids: typing.Optional[typing.Sequence[JobId]] = OMIT,
        metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobResponse:
        """
        Parameters
        ----------
        type : JobType
            The type of job

        operation : str
            the type of operation to perform on the data. For example, "export".

        source : JobSource

        destination : typing.Optional[JobDestination]

        config : typing.Optional[JobUpdateConfig]

        trigger : typing.Optional[Trigger]
            the type of trigger to use for this job

        status : typing.Optional[JobStatus]
            the status of the job

        progress : typing.Optional[int]
            the progress of the job. Whole number between 0 and 100

        file_id : typing.Optional[FileId]

        mode : typing.Optional[JobMode]
            the mode of the job

        input : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Input parameters for this job type.

        subject : typing.Optional[JobSubject]
            Subject parameters for this job type.

        outcome : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Outcome summary of job.

        info : typing.Optional[str]
            Current status of job in text

        managed : typing.Optional[bool]
            Indicates if Flatfile is managing the control flow of this job or if it is being manually tracked.

        environment_id : typing.Optional[EnvironmentId]
            The id of the environment this job belongs to

        part : typing.Optional[int]
            The part number of this job

        part_data : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            The data for this part of the job

        part_execution : typing.Optional[JobPartExecution]
            The execution mode for this part of the job

        parent_id : typing.Optional[JobId]
            The id of the parent job

        predecessor_ids : typing.Optional[typing.Sequence[JobId]]
            The ids of the jobs that must complete before this job can start

        metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Additional metadata for the job

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.create(
                type="workbook",
                operation="submitAction",
                source="us_wb_YOUR_ID",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "jobs",
            method="POST",
            json={
                "type": type,
                "operation": operation,
                "source": source,
                "destination": destination,
                "config": convert_and_respect_annotation_metadata(
                    object_=config, annotation=JobUpdateConfig, direction="write"
                ),
                "trigger": trigger,
                "status": status,
                "progress": progress,
                "fileId": file_id,
                "mode": mode,
                "input": input,
                "subject": convert_and_respect_annotation_metadata(
                    object_=subject, annotation=JobSubject, direction="write"
                ),
                "outcome": outcome,
                "info": info,
                "managed": managed,
                "environmentId": environment_id,
                "part": part,
                "partData": part_data,
                "partExecution": part_execution,
                "parentId": parent_id,
                "predecessorIds": predecessor_ids,
                "metadata": metadata,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get(self, job_id: JobId, *, request_options: typing.Optional[RequestOptions] = None) -> JobResponse:
        """
        Parameters
        ----------
        job_id : JobId
            The id of the job to return

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.get(
                job_id="us_jb_YOUR_ID",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update(
        self,
        job_id: JobId,
        *,
        config: typing.Optional[JobUpdateConfig] = OMIT,
        status: typing.Optional[JobStatus] = OMIT,
        progress: typing.Optional[int] = OMIT,
        outcome_acknowledged_at: typing.Optional[dt.datetime] = OMIT,
        info: typing.Optional[str] = OMIT,
        metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobResponse:
        """
        Parameters
        ----------
        job_id : JobId
            The id of the job to patch

        config : typing.Optional[JobUpdateConfig]

        status : typing.Optional[JobStatus]
            the status of the job

        progress : typing.Optional[int]
            the progress of the job. Whole number between 0 and 100

        outcome_acknowledged_at : typing.Optional[dt.datetime]
            the time that the job's outcome has been acknowledged by a user

        info : typing.Optional[str]
            Current status of job in text

        metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Additional metadata for the job

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile
        from flatfile.jobs import EmptyObject

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.update(
                job_id="us_jb_YOUR_ID",
                config=EmptyObject(),
                status="complete",
                progress=100,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}",
            method="PATCH",
            json={
                "config": convert_and_respect_annotation_metadata(
                    object_=config, annotation=JobUpdateConfig, direction="write"
                ),
                "status": status,
                "progress": progress,
                "outcomeAcknowledgedAt": outcome_acknowledged_at,
                "info": info,
                "metadata": metadata,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete(self, job_id: JobId, *, request_options: typing.Optional[RequestOptions] = None) -> Success:
        """
        Parameters
        ----------
        job_id : JobId
            The id of the job to delete

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Success

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.delete(
                job_id="us_jb_YOUR_ID",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    Success,
                    parse_obj_as(
                        type_=Success,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def execute(self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None) -> Success:
        """
        Execute a job and return the job

        Parameters
        ----------
        job_id : str
            ID of job to return

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Success

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.execute(
                job_id="us_jb_YOUR_ID",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/execute",
            method="POST",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    Success,
                    parse_obj_as(
                        type_=Success,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_execution_plan(
        self, job_id: JobId, *, request_options: typing.Optional[RequestOptions] = None
    ) -> JobPlanResponse:
        """
        Returns a single job's execution plan

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobPlanResponse

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.get_execution_plan(
                job_id="us_jb_YOUR_ID",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/plan",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobPlanResponse,
                    parse_obj_as(
                        type_=JobPlanResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_execution_plan(
        self,
        job_id_: JobId,
        *,
        file_id: FileId,
        job_id: JobId,
        field_mapping: typing.Sequence[Edge],
        unmapped_source_fields: typing.Sequence[SourceField],
        unmapped_destination_fields: typing.Sequence[DestinationField],
        program_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobPlanResponse:
        """
        Update a job's entire execution plan

        Parameters
        ----------
        job_id_ : JobId
            ID of job to return

        file_id : FileId

        job_id : JobId

        field_mapping : typing.Sequence[Edge]

        unmapped_source_fields : typing.Sequence[SourceField]

        unmapped_destination_fields : typing.Sequence[DestinationField]

        program_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobPlanResponse

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile
        from flatfile.jobs import DestinationField, Edge, SourceField
        from flatfile.property import Property_String

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.update_execution_plan(
                job_id_="us_jb_YOUR_ID",
                field_mapping=[
                    Edge(
                        source_field=Property_String(
                            key="firstName",
                        ),
                        destination_field=Property_String(
                            key="firstName",
                            label="First Name",
                        ),
                    ),
                    Edge(
                        source_field=Property_String(
                            key="lastName",
                        ),
                        destination_field=Property_String(
                            key="lastName",
                            label="Last Name",
                        ),
                    ),
                ],
                unmapped_source_fields=[
                    SourceField(
                        source_field=Property_String(
                            key="email",
                        ),
                    )
                ],
                unmapped_destination_fields=[
                    DestinationField(
                        destination_field=Property_String(
                            key="email",
                            label="Email",
                        ),
                    )
                ],
                file_id="us_fl_YOUR_ID",
                job_id="us_jb_YOUR_ID",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id_)}/plan",
            method="PUT",
            json={
                "fileId": file_id,
                "jobId": job_id,
                "fieldMapping": convert_and_respect_annotation_metadata(
                    object_=field_mapping, annotation=typing.Sequence[Edge], direction="write"
                ),
                "unmappedSourceFields": convert_and_respect_annotation_metadata(
                    object_=unmapped_source_fields, annotation=typing.Sequence[SourceField], direction="write"
                ),
                "unmappedDestinationFields": convert_and_respect_annotation_metadata(
                    object_=unmapped_destination_fields, annotation=typing.Sequence[DestinationField], direction="write"
                ),
                "programId": program_id,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobPlanResponse,
                    parse_obj_as(
                        type_=JobPlanResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_execution_plan_fields(
        self,
        job_id_: str,
        *,
        file_id: FileId,
        job_id: JobId,
        field_mapping: typing.Optional[typing.Sequence[Edge]] = OMIT,
        unmapped_source_fields: typing.Optional[typing.Sequence[SourceField]] = OMIT,
        unmapped_destination_fields: typing.Optional[typing.Sequence[DestinationField]] = OMIT,
        program_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobPlanResponse:
        """
        Update one or more individual fields on a job's execution plan

        Parameters
        ----------
        job_id_ : str
            ID of job to return

        file_id : FileId

        job_id : JobId

        field_mapping : typing.Optional[typing.Sequence[Edge]]

        unmapped_source_fields : typing.Optional[typing.Sequence[SourceField]]

        unmapped_destination_fields : typing.Optional[typing.Sequence[DestinationField]]

        program_id : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobPlanResponse

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.update_execution_plan_fields(
                job_id_="jobId",
                file_id="fileId",
                job_id="jobId",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id_)}/plan",
            method="PATCH",
            json={
                "fileId": file_id,
                "jobId": job_id,
                "fieldMapping": convert_and_respect_annotation_metadata(
                    object_=field_mapping, annotation=typing.Sequence[Edge], direction="write"
                ),
                "unmappedSourceFields": convert_and_respect_annotation_metadata(
                    object_=unmapped_source_fields, annotation=typing.Sequence[SourceField], direction="write"
                ),
                "unmappedDestinationFields": convert_and_respect_annotation_metadata(
                    object_=unmapped_destination_fields, annotation=typing.Sequence[DestinationField], direction="write"
                ),
                "programId": program_id,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobPlanResponse,
                    parse_obj_as(
                        type_=JobPlanResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def ack(
        self,
        job_id: JobId,
        *,
        request: typing.Optional[JobAckDetails] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobResponse:
        """
        Acknowledge a job and return the job

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        request : typing.Optional[JobAckDetails]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        import asyncio
        import datetime

        from flatfile import AsyncFlatfile
        from flatfile.jobs import JobAckDetails

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.ack(
                job_id="us_jb_YOUR_ID",
                request=JobAckDetails(
                    info="Acknowledged by user",
                    progress=100,
                    estimated_completion_at=datetime.datetime.fromisoformat(
                        "2023-10-30 20:04:32.074000+00:00",
                    ),
                ),
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/ack",
            method="POST",
            json=convert_and_respect_annotation_metadata(object_=request, annotation=JobAckDetails, direction="write"),
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def ack_outcome(
        self, job_id: JobId, *, request_options: typing.Optional[RequestOptions] = None
    ) -> JobResponse:
        """
        Acknowledge a job outcome and return the job

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.ack_outcome(
                job_id="us_jb_YOUR_ID",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/outcome/ack",
            method="POST",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def complete(
        self,
        job_id: JobId,
        *,
        request: typing.Optional[JobCompleteDetails] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobResponse:
        """
        Complete a job and return the job

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        request : typing.Optional[JobCompleteDetails]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile
        from flatfile.jobs import JobCompleteDetails, JobOutcome, JobOutcomeNext_Id

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.complete(
                job_id="us_jb_YOUR_ID",
                request=JobCompleteDetails(
                    outcome=JobOutcome(
                        acknowledge=True,
                        button_text="Acknowledge",
                        next=JobOutcomeNext_Id(
                            id="us_jb_YOUR_ID",
                        ),
                        heading="Success",
                        message="Job was successful",
                    ),
                    info="Job is Complete",
                ),
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/complete",
            method="POST",
            json=convert_and_respect_annotation_metadata(
                object_=request, annotation=JobCompleteDetails, direction="write"
            ),
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def fail(
        self,
        job_id: JobId,
        *,
        request: typing.Optional[JobCompleteDetails] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobResponse:
        """
        Fail a job and return the job

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        request : typing.Optional[JobCompleteDetails]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile
        from flatfile.jobs import JobCompleteDetails, JobOutcome, JobOutcomeNext_Id

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.fail(
                job_id="us_jb_YOUR_ID",
                request=JobCompleteDetails(
                    outcome=JobOutcome(
                        acknowledge=True,
                        button_text="Acknowledge",
                        next=JobOutcomeNext_Id(
                            id="us_jb_YOUR_ID",
                        ),
                        heading="Failed",
                        message="Job failed",
                    ),
                    info="Job was failed",
                ),
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/fail",
            method="POST",
            json=convert_and_respect_annotation_metadata(
                object_=request, annotation=JobCompleteDetails, direction="write"
            ),
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def cancel(
        self,
        job_id: JobId,
        *,
        request: typing.Optional[JobCancelDetails] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobResponse:
        """
        Cancel a job and return the job

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        request : typing.Optional[JobCancelDetails]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile
        from flatfile.jobs import JobCancelDetails

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.cancel(
                job_id="us_jb_YOUR_ID",
                request=JobCancelDetails(
                    info="Job was canceled",
                ),
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/cancel",
            method="POST",
            json=convert_and_respect_annotation_metadata(
                object_=request, annotation=JobCancelDetails, direction="write"
            ),
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def retry(self, job_id: JobId, *, request_options: typing.Optional[RequestOptions] = None) -> JobResponse:
        """
        Retry a failt job and return the job

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.retry(
                job_id="jobId",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/retry",
            method="POST",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def preview_mutation(
        self,
        *,
        sheet_id: SheetId,
        mutate_record: str,
        mutation_id: typing.Optional[str] = OMIT,
        snapshot_label: typing.Optional[str] = OMIT,
        snapshot_id: typing.Optional[str] = OMIT,
        filter: typing.Optional[Filter] = OMIT,
        filter_field: typing.Optional[FilterField] = OMIT,
        search_value: typing.Optional[SearchValue] = OMIT,
        search_field: typing.Optional[SearchField] = OMIT,
        q: typing.Optional[str] = OMIT,
        ids: typing.Optional[typing.Sequence[RecordId]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> DiffRecordsResponse:
        """
        Preview the results of a mutation

        Parameters
        ----------
        sheet_id : SheetId

        mutate_record : str
            A JavaScript function that will be run on each record in the sheet, it should return a mutated record.

        mutation_id : typing.Optional[str]
            If the mutation was generated through some sort of id-ed process, this links this job and that process.

        snapshot_label : typing.Optional[str]
            If specified, a snapshot will be generated with this label

        snapshot_id : typing.Optional[str]
            The generated snapshotId will be stored here

        filter : typing.Optional[Filter]

        filter_field : typing.Optional[FilterField]

        search_value : typing.Optional[SearchValue]

        search_field : typing.Optional[SearchField]

        q : typing.Optional[str]

        ids : typing.Optional[typing.Sequence[RecordId]]
            The Record Ids param (ids) is a list of record ids that can be passed to several record endpoints allowing the user to identify specific records to INCLUDE in the query, or specific records to EXCLUDE, depending on whether or not filters are being applied. When passing a query param that filters the record dataset, such as 'searchValue', or a 'filter' of 'valid' | 'error' | 'all', the 'ids' param will EXCLUDE those records from the filtered results. For basic queries that do not filter the dataset, passing record ids in the 'ids' param will limit the dataset to INCLUDE just those specific records

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        DiffRecordsResponse

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.preview_mutation(
                sheet_id="sheetId",
                mutate_record="mutateRecord",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "jobs/preview-mutation",
            method="POST",
            json={
                "sheetId": sheet_id,
                "mutateRecord": mutate_record,
                "mutationId": mutation_id,
                "snapshotLabel": snapshot_label,
                "snapshotId": snapshot_id,
                "filter": filter,
                "filterField": filter_field,
                "searchValue": search_value,
                "searchField": search_field,
                "q": q,
                "ids": ids,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    DiffRecordsResponse,
                    parse_obj_as(
                        type_=DiffRecordsResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def split(
        self,
        job_id: JobId,
        *,
        parts: JobParts,
        run_in_parallel: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> JobResponse:
        """
        Split a job and return the job

        Parameters
        ----------
        job_id : JobId
            ID of job to return

        parts : JobParts

        run_in_parallel : typing.Optional[bool]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        JobResponse

        Examples
        --------
        import asyncio

        from flatfile import AsyncFlatfile

        client = AsyncFlatfile(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.jobs.split(
                job_id="us_jb_YOUR_ID",
                parts=[{}],
                run_in_parallel=True,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"jobs/{jsonable_encoder(job_id)}/split",
            method="POST",
            json={
                "parts": convert_and_respect_annotation_metadata(object_=parts, annotation=JobParts, direction="write"),
                "runInParallel": run_in_parallel,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    JobResponse,
                    parse_obj_as(
                        type_=JobResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
